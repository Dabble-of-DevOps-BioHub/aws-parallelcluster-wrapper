{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "actual-services",
   "metadata": {},
   "source": [
    "# AWS ParallelCluster Programmatic Configuration\n",
    "\n",
    "Investigate the pcluster configure argument "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "adjusted-rebound",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pcluster\n",
    "import pcluster.configure.easyconfig as easyconfig\n",
    "import requests\n",
    "import random\n",
    "\n",
    "from pcluster.cluster_model import ClusterModel\n",
    "from pcluster.config.hit_converter import HitConverter\n",
    "from pcluster.config.pcluster_config import PclusterConfig\n",
    "from pcluster.config.validators import HEAD_NODE_UNSUPPORTED_INSTANCE_TYPES, HEAD_NODE_UNSUPPORTED_MESSAGE\n",
    "from pcluster.configure.networking import (\n",
    "    NetworkConfiguration,\n",
    "    PublicPrivateNetworkConfig,\n",
    "    automate_subnet_creation,\n",
    "    automate_vpc_with_subnet_creation,\n",
    ")\n",
    "from pcluster.configure.utils import get_regions, get_resource_tag, handle_client_exception, prompt, prompt_iterable\n",
    "from pcluster.utils import (\n",
    "    error,\n",
    "    get_default_instance_type,\n",
    "    get_region,\n",
    "    get_supported_az_for_multi_instance_types,\n",
    "    get_supported_az_for_one_instance_type,\n",
    "    get_supported_compute_instance_types,\n",
    "    get_supported_instance_types,\n",
    "    get_supported_os_for_scheduler,\n",
    "    get_supported_schedulers,\n",
    ")\n",
    "from pcluster.configure.easyconfig import ClusterConfigureHelper\n",
    "\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import sys\n",
    "from collections import OrderedDict\n",
    "import boto3\n",
    "import tempfile\n",
    "import string\n",
    "\n",
    "from datetime import datetime\n",
    "from jinja2 import Environment, BaseLoader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "specified-sugar",
   "metadata": {},
   "source": [
    "## Create A Project ID\n",
    "\n",
    "Create a random project ID for the state, buckets, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "separate-circulation",
   "metadata": {},
   "outputs": [],
   "source": [
    "today = datetime.today().strftime('%Y%m%d')\n",
    "today = '20210127'\n",
    "\n",
    "N = 6\n",
    "random_string = ''.join(random.choices(string.ascii_lowercase + string.digits, k=N))\n",
    "random_string\n",
    "\n",
    "ID='{today}-{random_string}'.format(today=today, random_string=random_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "private-burlington",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are all variables that will be passed in and supplied through cookiecutter\n",
    "# We'll also grab the terraform output\n",
    "# We'll use pcluster to create the subnets because it's very picky about subnets\n",
    "\n",
    "CONFIG = {\n",
    "    'id': ID,\n",
    "    'hosted_zone_id': '',\n",
    "    '_copy_without_render': [\n",
    "                'files/installation/deploy_jupyterhub/jupyterhub_config.py',\n",
    "    ],\n",
    "    'project': 'slurm-cluster',\n",
    "    'stage': 'development',\n",
    "    'vpc_id': 'vpc-63c3bb0b',\n",
    "    'aws_region': 'eu-west-2',\n",
    "    'custom_ami_id': '',\n",
    "    'cloudformation_stack': 'parallelcluster-{{cookiecutter.project}}-{{cookiecutter.id}}-{{cookiecutter.stage}}',\n",
    "    # These all get read in from terraform\n",
    "    's3_installation_bucket': \"{{cookiecutter.project}}-{{cookiecutter.id}}-{{cookiecutter.stage}}-installation\",\n",
    "    's3_user_data_bucket': \"{{cookiecutter.project}}-{{cookiecutter.id}}-{{cookiecutter.stage}}-user-data\",\n",
    "    's3_admin_bucket': \"{{cookiecutter.project}}-{{cookiecutter.id}}-{{cookiecutter.stage}}-admin\",\n",
    "    'tags': {\n",
    "        'Name': '{{cookiecutter.project}}-{{cookiecutter.id}}-{{cookiecutter.stage}}',\n",
    "        'Project': '{{cookiecutter.project}}',\n",
    "        'Stage': '{{cookiecutter.stage}}',\n",
    "\n",
    "    },\n",
    "    # Terraform recipe vars\n",
    "    'terraform_recipes': {\n",
    "        # Bootstrap the state\n",
    "        'terraform_state': 'terraform-state',\n",
    "        # Supply the resources, build the custom AMI\n",
    "        'pcluster_resources': 'pcluster-resources',\n",
    "        # After install all the apps - easybuild, modules, etc\n",
    "        'pcluster_apps': 'pcluster-apps',\n",
    "    },\n",
    "    # Terraform state Vars\n",
    "    # these end up looking different because the module tacks on some names\n",
    "    \"terraform_state\": {\n",
    "        \"s3_bucket\": \"{{cookiecutter.project}}-{{cookiecutter.id}}\",\n",
    "        \"s3_bucket_full_name\": \"{{cookiecutter.project}}-{{cookiecutter.id}}-{{cookiecutter.stage}}-terraform-state\",\n",
    "        \"dynamo_db_table\": \"{{cookiecutter.project}}-{{cookiecutter.id}}-{{cookiecutter.stage}}-terraform-state-lock\",\n",
    "    },\n",
    "    # Store the terraform output\n",
    "    'terraform_output': {\n",
    "        'terraform_state': {},\n",
    "        'pcluster_resources': {},\n",
    "        'pcluster_apps': {},\n",
    "    },\n",
    "    # PCluster Vars\n",
    "    'pcluster': {\n",
    "        'master_instance_type': 't3a.2xlarge',\n",
    "        'scheduler': 'slurm',\n",
    "        'base_os': 'alinux2',\n",
    "        'pcluster_version': '2.10.1',\n",
    "        'key_pair': '',\n",
    "        'min_cluster_size': 0,\n",
    "        'max_cluster_size': 100,\n",
    "        'head_node_instance_type': 't3a.2xlarge',\n",
    "        # This doesn't matter because we're using queues\n",
    "        # But still used\n",
    "        'compute_node_instance_type': 't3a.2xlarge',\n",
    "        'master_subnet_id': '',\n",
    "        'compute_subnet_id': '',\n",
    "        'compute_resources': [\n",
    "            {\n",
    "                'instance_type': 't3a.medium',\n",
    "                'min_count': 0,\n",
    "                'max_count': 100,\n",
    "            },\n",
    "            {\n",
    "                'instance_type': 't3a.large',\n",
    "                'min_count': 0,\n",
    "                'max_count': 100,\n",
    "            },\n",
    "            {\n",
    "                'instance_type': 't3a.2xlarge',\n",
    "                'min_count': 0,\n",
    "                'max_count': 100,\n",
    "            },\n",
    "            {\n",
    "                'instance_type': 'm4.large',\n",
    "                'min_count': 0,\n",
    "                'max_count': 100,\n",
    "            },\n",
    "            {\n",
    "                'instance_type': 'm4.xlarge',\n",
    "                'min_count': 0,\n",
    "                'max_count': 100,\n",
    "            },\n",
    "            {\n",
    "                'instance_type': 'm4.2xlarge',\n",
    "                'min_count': 0,\n",
    "                'max_count': 100,\n",
    "            },\n",
    "            {\n",
    "                'instance_type': 'g4dn.xlarge',\n",
    "                'min_count': 0,\n",
    "                'max_count': 100,\n",
    "            },\n",
    "            {\n",
    "                'instance_type': 'g4dn.2xlarge',\n",
    "                'min_count': 0,\n",
    "                'max_count': 100,\n",
    "            },\n",
    "            {\n",
    "                'instance_type': 'g4dn.4xlarge',\n",
    "                'min_count': 0,\n",
    "                'max_count': 100,\n",
    "            },\n",
    "        ],\n",
    "        'queues': [\n",
    "            {\n",
    "                'name': 'dev',\n",
    "                'enable_efa': False,\n",
    "                'enable_efa_gdr': False,\n",
    "                'compute_resource_instance_types': ['t3a.medium', 't3a.large', 't3a.2xlarge'],\n",
    "            },\n",
    "            {\n",
    "                'name': 'cpu',\n",
    "                'enable_efa': False,\n",
    "                'enable_efa_gdr': False,\n",
    "                'compute_resource_instance_types': ['m4.large', 'm4.xlarge', 'm4.2xlarge'],\n",
    "            },\n",
    "            {\n",
    "                'name': 'gpu',\n",
    "                'enable_efa': False,\n",
    "                'enable_efa_gdr': False,\n",
    "                'compute_resource_instance_types': ['g4dn.xlarge', 'g4dn.2xlarge', 'g4dn.4xlarge'],\n",
    "            },\n",
    "        ],\n",
    "        'queue_settings': '',\n",
    "        'efs_resources': [\n",
    "            {\n",
    "                \"name\": \"apps\",\n",
    "                \"efs_id\": False,\n",
    "                \"performance_mode\": \"generalPurpose\"\n",
    "            },\n",
    "            {\n",
    "                \"name\": \"scratch\",\n",
    "                \"efs_id\": False,\n",
    "                \"performance_mode\": \"maxIO\"\n",
    "            }\n",
    "        ],\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "BASE_DIR='/home/jovyan/etcembly/'\n",
    "os.makedirs(BASE_DIR, exist_ok=True)\n",
    "\n",
    "with open(os.path.join(BASE_DIR, 'cookiecutter.json'), 'w') as outfile:\n",
    "    json.dump(CONFIG, outfile, indent=4)    \n",
    "\n",
    "with open('/home/jovyan/app/aws_parallelcluster_wrapper/_cookiecutter_templates/terraform-modules/terraform-state/cookiecutter.json', 'w') as outfile:\n",
    "    json.dump(CONFIG, outfile, indent=4)\n",
    "        \n",
    "    \n",
    "with open('/home/jovyan/app/aws_parallelcluster_wrapper/_cookiecutter_templates/terraform-modules/pcluster-resources/cookiecutter.json', 'w') as outfile:\n",
    "    json.dump(CONFIG, outfile, indent=4)\n",
    "    \n",
    "with open('/home/jovyan/app/aws_parallelcluster_wrapper/_cookiecutter_templates/terraform-modules/pcluster-apps/cookiecutter.json', 'w') as outfile:\n",
    "    json.dump(CONFIG, outfile, indent=4)\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "enabling-monaco",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "intellectual-blend",
   "metadata": {},
   "source": [
    "Then run\n",
    "\n",
    "```bash\n",
    "aws_parallelcluster_wrapper  apply-terraform-state  --config ~/etcembly/cookiecutter.json --outdir ~/etcembly/project/slurm-cluster-development/ \n",
    "aws_parallelcluster_wrapper deploy-pcluster-resources  --config ~/etcembly/cookiecutter.json --outdir ~/etcembly/project/slurm-cluster-development/ --apply\n",
    "aws_parallelcluster_wrapper create-pcluster  --config ~/etcembly/cookiecutter.json --outdir ~/etcembly/project/slurm-cluster-development/ --apply\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "instructional-intellectual",
   "metadata": {},
   "source": [
    "## PConfig Cluster Section"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vulnerable-updating",
   "metadata": {},
   "source": [
    "### Region\n",
    "\n",
    "Just run a check here to make sure that there is a valid region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "divine-domain",
   "metadata": {},
   "outputs": [],
   "source": [
    "#available_regions = get_regions()\n",
    "\n",
    "# London\n",
    "# region = 'eu-west-2'\n",
    "os.environ[\"AWS_DEFAULT_REGION\"] = CONFIG['aws_region']\n",
    "\n",
    "#pcluster_config.region = region"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "attached-advertiser",
   "metadata": {},
   "source": [
    "## Cloudformation stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "resident-cleaners",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "unexpected-cursor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'858286506743'"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sts_client = boto3.client(\"sts\")\n",
    "account_id = sts_client.get_caller_identity()[\"Account\"]\n",
    "account_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "bigger-place",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = boto3.client('cloudformation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "amended-palace",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Exports': [],\n",
       " 'ResponseMetadata': {'RequestId': '7108a5c7-b22a-4a32-bd7f-5b2d092370d6',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '7108a5c7-b22a-4a32-bd7f-5b2d092370d6',\n",
       "   'content-type': 'text/xml',\n",
       "   'content-length': '272',\n",
       "   'date': 'Wed, 27 Jan 2021 12:19:23 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.list_exports()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "activated-router",
   "metadata": {},
   "outputs": [],
   "source": [
    "stacks = client.describe_stacks(StackName='parallelcluster-slurm-cluster-20210127-development',)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "alive-diary",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stacks['Stacks'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "smoking-agenda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['StackId', 'StackName', 'Description', 'Parameters', 'CreationTime', 'RollbackConfiguration', 'StackStatus', 'DisableRollback', 'NotificationARNs', 'Capabilities', 'Outputs', 'Tags', 'EnableTerminationProtection', 'DriftInformation'])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacks['Stacks'][0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "brown-sensitivity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ParameterKey: MasterSubnetId\n",
      "ParameterKey: MasterRootVolumeSize\n",
      "ParameterKey: MasterInstanceType\n"
     ]
    }
   ],
   "source": [
    "for parameter in stacks['Stacks'][0]['Parameters']:\n",
    "    key = parameter['ParameterKey']\n",
    "    if 'Master' in key:\n",
    "        print('ParameterKey: {}'.format(parameter['ParameterKey']))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "fewer-dominican",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'OutputKey': 'ArtifactS3RootDirectory', 'OutputValue': 'parallelcluster-slurm-cluster-20210127-develop-28jog97ymlhz3z72', 'Description': 'Root directory in S3 bucket where cluster artifacts are stored'}\n",
      "{'OutputKey': 'IsHITCluster', 'OutputValue': 'true'}\n",
      "{'OutputKey': 'ClusterUser', 'OutputValue': 'ec2-user', 'Description': 'Username to login to head node'}\n",
      "{'OutputKey': 'MasterPrivateIP', 'OutputValue': '172.31.97.236', 'Description': 'Private IP Address of the head node'}\n",
      "{'OutputKey': 'ResourcesS3Bucket', 'OutputValue': 'parallelcluster-p4b4uzx457i1111h', 'Description': 'S3 user bucket where AWS ParallelCluster resources are stored'}\n",
      "{'OutputKey': 'ClusterConfigMetadata', 'OutputValue': '{\"sections\": {\"cluster\": [\"default\"], \"scaling\": [\"default\"], \"vpc\": [\"default\"]}}'}\n",
      "{'OutputKey': 'GangliaPrivateURL', 'OutputValue': 'http://172.31.97.236/ganglia/', 'Description': 'Private URL to access Ganglia (disabled by default)'}\n"
     ]
    }
   ],
   "source": [
    "for output in stacks['Stacks'][0]['Outputs']:\n",
    "    print(output)\n",
    "    #key = parameter['ParameterKey']\n",
    "    #if 'Master' in key:\n",
    "    #    print('ParameterKey: {}'.format(parameter['ParameterKey']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "compatible-performer",
   "metadata": {},
   "outputs": [
    {
     "ename": "ClientError",
     "evalue": "An error occurred (ValidationError) when calling the DescribeStackResources operation: Stack with id parallelcluster-slurm-cluster-20210127-development does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mClientError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-67d7cfd6c76b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcfn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mboto3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cloudformation'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmy_stack_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'parallelcluster-slurm-cluster-20210127-development'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescribe_stack_resources\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mStackName\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'PhysicalResourceId'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'StackResources'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescribe_stack_resources\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mStackName\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmy_stack_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'StackResources'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    355\u001b[0m                     \"%s() only accepts keyword arguments.\" % py_operation_name)\n\u001b[1;32m    356\u001b[0m             \u001b[0;31m# The \"self\" in this scope is referring to the BaseClient.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_api_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperation_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m         \u001b[0m_api_call\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpy_operation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m    674\u001b[0m             \u001b[0merror_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Error\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Code\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m             \u001b[0merror_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0merror_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed_response\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mClientError\u001b[0m: An error occurred (ValidationError) when calling the DescribeStackResources operation: Stack with id parallelcluster-slurm-cluster-20210127-development does not exist"
     ]
    }
   ],
   "source": [
    "cfn = boto3.client('cloudformation')\n",
    "my_stack_name='parallelcluster-slurm-cluster-20210127-development'\n",
    "list(map(lambda x: cfn.describe_stack_resources(StackName=x['PhysicalResourceId'])['StackResources'], cfn.describe_stack_resources(StackName=my_stack_name)['StackResources']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "periodic-universal",
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_resources = cfn.describe_stack_resources(StackName=my_stack_name)['StackResources']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "proprietary-soldier",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'StackName': 'parallelcluster-slurm-cluster-20210127-development',\n",
       " 'StackId': 'arn:aws:cloudformation:us-east-1:858286506743:stack/parallelcluster-slurm-cluster-20210127-development/872a7680-6096-11eb-8ea4-1266e578c117',\n",
       " 'LogicalResourceId': 'CleanupResourcesFunction',\n",
       " 'PhysicalResourceId': 'pcluster-CleanupResources-872a7680-6096-11eb-8ea4-1266e578c117',\n",
       " 'ResourceType': 'AWS::Lambda::Function',\n",
       " 'Timestamp': datetime.datetime(2021, 1, 27, 11, 55, 47, 332000, tzinfo=tzlocal()),\n",
       " 'ResourceStatus': 'CREATE_COMPLETE',\n",
       " 'DriftInformation': {'StackResourceDriftStatus': 'NOT_CHECKED'}}"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stack_resources[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "geological-springer",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
